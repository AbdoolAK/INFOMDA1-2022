---
title: "Practical 1"
author: "Lorenzo Occelli"
date: "16-09-2022"
output:
  html_document:
    toc: yes
    toc_depth: 1
    toc_float: yes
    df_print: paged
    theme: paper
    highlight: pygments
    pandoc_args: --output=P1_LorenzoOccelli.html
  pdf_document:
    toc: yes
    toc_depth: '1'
fontsize: 12pt
urlcolor: blue
mainfont: Arial
---

```{r load_packages, message = FALSE, warning = FALSE}
library(ISLR)
library(tidyverse)
library(haven)
library(readxl)
```

---

1. __Run the following code in `R` and inspect their data types using the `class()` function. Try to guess beforehand what their types will be!__

---

```{r 1}
object_1 <- 1:5
object_2 <- 1L:5L
object_3 <- "-123.456"
object_4 <- as.numeric(object_2)
object_5 <- letters[object_1]
object_6 <- as.factor(rep(object_5, 2))
object_7 <- c(1, 2, 3, "4", "5", "6")
```

object_1 is an "integer" \
object_2 is an "integer" \
object_3 is a "character" \
object_4 is a "numeric" \
object_5 is a "character" \
object_6 is a "factor" \
object_7 is a "character" \

---

2. __Convert `object_7` back to a vector of numbers using the `as.numeric()` function__

---

```{r 2}
object_7 <- as.numeric(object_7)
```

---

3. __Make a list called `objects` containing object 1 to 7 using the `list()` function.__

---

```{r 3}
objects <- list(object_1, object_2, object_3, object_4, object_5, object_6, object_7)
```

If I want to select a single element of the list, as object_3...
```{r 3b}
elem <- objects[[3]]
```
It's interesting that R start the indexes from 1 and not 0 as most of other programming languages.

---

4. __Make a data frame out of `object_1`, `object_2`, and `object_5` using the `data.frame()` function__

---
```{r 4}
data <- data.frame(obj1 = object_1, obj2 = object_2, obj3 = object_5)
```
---

5. __Useful functions for determining the size of a data frame are `ncol()` and `nrow()`.__

---
```{r 5}
ncol <- ncol(data)
nrow <- nrow(data)
```

6. __Use the function `read_csv()` to import the file "data/googleplaystore.csv" and store it in a variable called `apps`.__

```{r 6}
apps <- read_csv("data/googleplaystore.csv")
```
---

7. __Did any column get a variable type you did not expect?__

---

```{r 7}
print(class(apps$Installs))
print(class(apps$Price))
```

The latter columns should contain numeric types, instead of character ones.

---

8. __Use the function `head()` to look at the first few rows of the `apps` dataset__

---

```{r 8}
head(apps)
```

---

9. __Repeat steps 5, 6, and 7 but now for "data/students.xlsx" (NB: You'll need a function from the package `readxl`). Also try out the function `tail()` and `View()`.__

---

```{r 9}
students <- read_xlsx("data/students.xlsx")
print(class(students$student_number))
print(class(students$grade))
```


```{r 9c}
head(students)
tail(students)
```

---

10. __Create a summary of the three columns in the students dataset using the `summary()` function. What is the range of the grades achieved by the students?__

---

```{r}
summary(students)
```
From the summary function appears that the students got grades between 4.844 and 9.291.

---

11. __Look at the help pages for `filter()` (especially the examples) and show the students with a grade lower than 5.5__

---

```{r 11}
filter(students, grade < 5.5)
```

---

12. __Show only the students with a grade higher than 8 from programme A__

---

```{r 12}
filter(students, grade > 8 & programme == "A")
```

---

13. __Sort the students dataset such that the students from programme A are on top of the data frame and within the programmes the highest grades come first.__

---

```{r 13}
arrange(students, programme, -grade)
```

---

14. __Show only the `student_number` and `programme` columns from the students dataset__ 

---

```{r 14}
select(students, student_number, programme)
```

```{r 15}
students <- mutate(students, pass = grade > 5.5)
students
```

---

15. __Use `mutate()` and `recode()` to change the codes in the programme column of the students dataset to their names. Store the result in a variable called `students_recoded`__

---

```{r 15b}
students_recoded <- mutate(students, programme = recode(programme, "A" = "Science", "B" = "Social Science"))
```

---

16. __Create a data processing pipeline that (a) loads the apps dataset, (b) parses the number of installs as 'Downloads' variable using `mutate` and `parse_number()`, (c) shows only apps with more than 500 000 000 downloads, (d) orders them by rating (best on top), and (e) shows only the relevant columns (you can choose which are relevant, but select at least the `Rating` and `Category` variables). Save the result under the name `popular_apps`.__

---

```{r 16}
popular_apps <- read_csv("data/googleplaystore.csv") %>% mutate(Downloads = parse_number(Installs)) %>% filter(Downloads > 5e8) %>% arrange(-Rating) %>% select(App, Rating, Downloads, Category) %>% distinct(App, .keep_all = TRUE)
```

```{r 16b}
students %>% summarise(
    mean = mean(grade), 
    variance = var(grade), 
    min = min(grade), 
    max = max(grade)
  )
```

---

17. __Show the median, minimum, and maximum for the popular apps dataset you made in the previous assignment.__

---

```{r 17}
popular_apps %>% summarise(median = median(Rating), min = min(Rating), max = max(Rating))
```


```{r 17b}
mad <- function(x) {
  median(abs(x - median(x)))
}
students %>% summarise(mad = mad(grade))
```

---

18. __Add the median absolute deviation to the summaries you made before__

---

```{r 18}
popular_apps %>% summarise(
  median = median(Rating), 
  min = min(Rating), 
  max = max(Rating),
  mad = mad(Rating)
  )
```

---

19. __Create a grouped summary of the ratings per category in the popular apps dataset.__

---

```{r 19}
popular_apps %>% 
  group_by(Category) %>% 
  summarise(
  median = median(Rating), 
  min = min(Rating), 
  max = max(Rating),
  mad = mad(Rating)
  )
```

## Final Exercise

---

20. __Create an interesting summary based on the Google play store apps dataset. An example could be "do games get higher ratings than communication apps?"__

---

Does more downloads implies higher rating?

```{r 20}
apps %>%
  mutate(Downloads = parse_number(Installs)) %>% 
  select(Rating, Downloads) %>% 
  filter(Downloads > 0) %>% 
  group_by(Downloads) %>% 
  summarise(mean = mean(Rating, na.rm=TRUE), 
  min = min(Rating, na.rm=TRUE), 
  max = max(Rating, na.rm=TRUE),
  )
```
Apparently not! The highest rating belongs to the apps with smaller amount of downloads, while the worst rating is found for app with 5000 to 10000 downloads. Must be pointed out that for the app with fewer downloads the statistics could be spoilt by the limited number of the sample, that we can assume to be composed mainly by users very interested in the content of the app, then more likely to give high ratings to the app itself.







